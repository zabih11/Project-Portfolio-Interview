{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2f9580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\User/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2024-3-22 Python-3.11.5 torch-2.2.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3070, 8191MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7050580 parameters, 0 gradients, 15.9 GFLOPs\n",
      "Adding AutoShape... \n",
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\User/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2024-3-22 Python-3.11.5 torch-2.2.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3070, 8191MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7047883 parameters, 0 gradients, 15.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models moved to CPU\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import requests\n",
    "import customtkinter as ctk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "# Load the YOLOv5 model\n",
    "default_model = torch.hub.load('ultralytics/yolov5', 'custom', path='bestdef.pt', force_reload=True) #depends on the exp number\n",
    "orange_model = torch.hub.load('ultralytics/yolov5', 'custom', path='besto.pt', force_reload=True)\n",
    "\n",
    "# Set confidence threshold\n",
    "default_model.conf = 0.7\n",
    "orange_model.conf = 0.5\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Move the model to CPU\n",
    "    default_model = default_model.to('cpu')\n",
    "    orange_model = orange_model.to('cpu')\n",
    "    print(\"Models moved to CPU\")\n",
    "else:\n",
    "    print(\"CUDA (GPU) is not available, model will run on CPU by default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07591af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "import torch\n",
    "import serial.tools.list_ports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import speech_recognition as sr\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf3f738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COM5 - Arduino Uno (COM5)\n"
     ]
    }
   ],
   "source": [
    "ports=serial.tools.list_ports.comports()\n",
    "\n",
    "portsList=[]\n",
    "for onePort in ports:\n",
    "    portsList.append(str(onePort))\n",
    "    print(str(onePort))\n",
    "    \n",
    "#val1=input(\"First Port: COM\")\n",
    "val1=5\n",
    "PortVar1='COM'+str(val1)\n",
    "\n",
    "port1=serial.Serial(PortVar1, 9600, timeout=0.1)  \n",
    "#port1.open()\n",
    "#port1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c25b9761",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected manual mode\n",
      "Quitting\n",
      "95 84\n",
      "97 86\n",
      "99 88\n",
      "101 90\n",
      "103 92\n",
      "105 94\n",
      "107 96\n",
      "109 98\n",
      "111 100\n",
      "113 102\n",
      "115 104\n",
      "117 106\n",
      "119 108\n",
      "121 110\n",
      "119 112\n",
      "121 114\n",
      "119 116\n",
      "121 118\n",
      "119 120\n",
      "121 122\n",
      "119 124\n",
      "121 126\n",
      "119 128\n",
      "121 130\n",
      "119 132\n",
      "121 134\n",
      "119 136\n",
      "121 138\n",
      "119 140\n",
      "121 142\n",
      "119 144\n",
      "121 146\n",
      "119 148\n"
     ]
    }
   ],
   "source": [
    "sending=True\n",
    "voice_override=False\n",
    "mp_drawing=mp.solutions.drawing_utils\n",
    "mp_hands=mp.solutions.hands\n",
    "mp_holistic=mp.solutions.holistic\n",
    "\n",
    "def initial_scan(livespeed, cpd, spd, ppd, tpd, mode):\n",
    "    command='turn left'\n",
    "    (livespeed,cpd,spd,ppd,tpd,\n",
    "    circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)\n",
    "    print(command)\n",
    "    #send instruction\n",
    "    bigmode=1\n",
    "    if sending==True:\n",
    "        pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "\n",
    "# Gets the left and right hand (used by manual control)\n",
    "def get_label(index, hand, results):\n",
    "\n",
    "    output = None\n",
    "    label= 'na'\n",
    "    LC=tuple(np.multiply(\n",
    "                    np.array((hand.landmark[mp_hands.HandLandmark.THUMB_IP].x, hand.landmark[mp_hands.HandLandmark.THUMB_IP].y)),\n",
    "                    [640,480]).astype(int))\n",
    "    RC=tuple(np.multiply(\n",
    "                    np.array((hand.landmark[mp_hands.HandLandmark.PINKY_MCP].x, hand.landmark[mp_hands.HandLandmark.PINKY_MCP].y)),\n",
    "                    [640,480]).astype(int))\n",
    "    coords=(0,0)\n",
    "    if index == 0:\n",
    "        label = results.multi_handedness[0].classification[0].label\n",
    "        score = results.multi_handedness[0].classification[0].score\n",
    "        text = '{} {}'.format(label, round(score, 2))\n",
    "        if label == 'Left':\n",
    "            coords = LC\n",
    "        if label == 'Right':\n",
    "            coords = RC\n",
    "    if index == 1:\n",
    "        label = results.multi_handedness[1].classification[0].label\n",
    "        score = results.multi_handedness[1].classification[0].score\n",
    "        text = '{} {}'.format(label, round(score, 2))\n",
    "        if label == 'Left':\n",
    "            coords = LC\n",
    "        if label == 'Right':\n",
    "            coords = RC\n",
    "    if label=='na':\n",
    "        text='na'\n",
    "    output = text, coords\n",
    "    return output\n",
    "\n",
    "def transcribe_microphone():\n",
    "    # Initialize recognizer\n",
    "    recognizer = sr.Recognizer()\n",
    "    specific_class='None'\n",
    "    # Use microphone as audio source\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Speak something...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)  # Adjust for noise\n",
    "        audio = recognizer.listen(source)  # Listen for audio input\n",
    "\n",
    "    try:\n",
    "        print(\"Transcribing...\")\n",
    "        text = recognizer.recognize_google(audio)  # Use Google Speech Recognition\n",
    "        print(\"You said:\", text)\n",
    "        \n",
    "        if 'override' in text.lower() or 'control' in text.lower() or 'manual' in text.lower():\n",
    "            mode='manual'\n",
    "            print(\"Command: manual\")\n",
    "            return mode # Return immediately after setting the mode\n",
    "\n",
    "        elif 'default' in text.lower():\n",
    "            mode='default'\n",
    "            print('Command: default')\n",
    "            return mode\n",
    "        elif 'quit' in text.lower() or 'turn off' in text.lower():\n",
    "            mode='quit'\n",
    "            print('goodbye.')\n",
    "            return mode\n",
    "\n",
    "        #object\n",
    "        trigger_words=['get', 'grab', 'fetch', 'pick up', 'bring']\n",
    "        for trigger in trigger_words:\n",
    "            if trigger in text.lower():\n",
    "                #mode='YOLO'\n",
    "                #check class\n",
    "                classes = ['orange', 'fork', 'phone', 'can', 'mouse']\n",
    "                specific_class = None\n",
    "                for cls in classes:\n",
    "                    if cls in text.lower():\n",
    "                        specific_class = cls\n",
    "                        break  # Select the first class instance and exit loop\n",
    "                if specific_class:\n",
    "                    mode=specific_class\n",
    "                    print(f\"Command: {trigger}, Class: {specific_class}\")\n",
    "                    return mode\n",
    "                else:\n",
    "                    print(f\"No specific class mentioned after '{trigger}'.\")\n",
    "                    return None\n",
    "                break  # Exit loop if any command is found\n",
    "                \n",
    "        print(\"No command detected.\")\n",
    "        \n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, could not understand audio.\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Error:\", e)\n",
    "    return None\n",
    "    \n",
    "def extract_abcM(joint):\n",
    "    a = np.array([hand.landmark[joint[0]].x, hand.landmark[joint[0]].y, hand.landmark[joint[0]].z]) # First coord\n",
    "    b = np.array([hand.landmark[joint[1]].x, hand.landmark[joint[1]].y, hand.landmark[joint[1]].z]) # Second coord\n",
    "    c = np.array([hand.landmark[joint[2]].x, hand.landmark[joint[2]].y, hand.landmark[joint[2]].z]) # Third coord\n",
    "    M = np.array([(hand.landmark[joint[0]].x + hand.landmark[joint[2]].x)/2, \n",
    "                  (hand.landmark[joint[0]].y + hand.landmark[joint[2]].y)/2,\n",
    "                  (hand.landmark[joint[0]].z + hand.landmark[joint[2]].z)/2]) # mid point coord\n",
    "    J = np.array([M[0], M[1], a[2]]) # J = point on xy plane with 'a', paralell z-axis to M\n",
    "    \n",
    "    return a,b,c,M,J\n",
    "\n",
    "def next_angle(angle_read_from_mediapipe, joint_angle_from_memory):\n",
    "    stored_target= round(angle_read_from_mediapipe/ 10) * 10    # get nearest 10 degree\n",
    "    if abs(joint_angle_from_memory-stored_target)>=6:   # check prev vs target\n",
    "        \n",
    "        if joint_angle_from_memory>stored_target:      #find direction to adjust\n",
    "            output_angle=joint_angle_from_memory-2     #output it\n",
    "        elif joint_angle_from_memory<stored_target:\n",
    "            output_angle=joint_angle_from_memory+2     #output it\n",
    "       \n",
    "        #print(previousj1,j1,stored_target,outputj1) \n",
    "        \n",
    "        joint_angle_from_memory=output_angle              #record the angle to memory\n",
    "    else:                                           #angle near target\n",
    "        output_angle=joint_angle_from_memory               #use angle from memory\n",
    "        \n",
    "    return output_angle, joint_angle_from_memory\n",
    "\n",
    "def render_result(image,actual_text,text_position):\n",
    "    cv2.putText(image, actual_text, tuple(np.multiply(text_position, [640, 480]).astype(int)),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "def pass_instruction_base(bigmode, Circle_Dir,Square_Dir,Plus_Dir,Triangle_Dir, Speed):\n",
    "    Instruction = f\"{bigmode} {Circle_Dir} {Square_Dir} {Plus_Dir} {Triangle_Dir} {Speed} \"\n",
    "    port1.write(Instruction.encode('utf-8'))\n",
    "    \n",
    "def pass_instruction_arm(bigmode, previousj1,  previousj2, previousj3, previousj4, pointless):\n",
    "    Instruction = f\"{bigmode} {previousj1} {previousj2} {previousj3} {previousj4} {pointless}\"\n",
    "    port1.write(Instruction.encode('utf-8'))\n",
    "  \n",
    "def fold_angle(a,b,c):\n",
    "    px=abs(c[0]-a[0])\n",
    "    py=abs(c[1]-a[1])\n",
    "    pz=abs(c[2]-a[2])\n",
    "    L2=np.linalg.norm(b - c)\n",
    "    L3=np.linalg.norm(b - a)\n",
    "    fold_angle=np.arccos((px**2+py**2+pz**2-L3**2-L2**2)/(2*L3*L2))\n",
    "    fold_angle= fold_angle*180/np.pi\n",
    "    \n",
    "    return fold_angle\n",
    "\n",
    "def curled_finger(a,b,c):\n",
    "    px=abs(c[0]-a[0])\n",
    "    py=abs(c[1]-a[1])\n",
    "    pz=abs(c[2]-a[2])\n",
    "    L2=np.linalg.norm(b - c)\n",
    "    L3=np.linalg.norm(b - a)\n",
    "    fold_angle=np.arccos((px**2+py**2+pz**2-L3**2-L2**2)/(2*L3*L2))\n",
    "    fold_angle= fold_angle*180/np.pi\n",
    "    \n",
    "    if fold_angle>100:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def straight_finger(a,b,c):\n",
    "    px=abs(c[0]-a[0])\n",
    "    py=abs(c[1]-a[1])\n",
    "    pz=abs(c[2]-a[2])\n",
    "    L2=np.linalg.norm(b - c)\n",
    "    L3=np.linalg.norm(b - a)\n",
    "    fold_angle=np.arccos((px**2+py**2+pz**2-L3**2-L2**2)/(2*L3*L2))\n",
    "    fold_angle= fold_angle*180/np.pi\n",
    "    \n",
    "    if fold_angle<30:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def fingers_straight():\n",
    "    joint=[20,18,17]\n",
    "    a,b,c,M,J = extract_abcM(joint)    #20,18,17\n",
    "    #con3 pinky down\n",
    "    con3=straight_finger(a,b,c)\n",
    "    \n",
    "    joint=[16,14,13]\n",
    "    a,b,c,M,J = extract_abcM(joint) #16,14,13\n",
    "    #con4 ring down\n",
    "    con4=straight_finger(a,b,c)\n",
    "   \n",
    "    joint=[12,10,9]\n",
    "    a,b,c,M,J = extract_abcM(joint)  #12,10,9\n",
    "    #con5 middle down\n",
    "    con5=straight_finger(a,b,c)\n",
    "        \n",
    "    joint=[8,6,5]\n",
    "    a,b,c,M,J = extract_abcM(joint)   #8,6,5 \n",
    "    #con6 index down   \n",
    "    con6=straight_finger(a,b,c)\n",
    "    \n",
    "    if con3==True and con4==True and con5==True and con6==True:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def fingers_curled():\n",
    "    joint=[20,18,17]\n",
    "    a,b,c,M,J = extract_abcM(joint)    #20,18,17\n",
    "    #con3 pinky down\n",
    "    con3=curled_finger(a,b,c)\n",
    "    \n",
    "    joint=[16,14,13]\n",
    "    a,b,c,M,J = extract_abcM(joint) #16,14,13\n",
    "    #con4 ring down\n",
    "    con4=curled_finger(a,b,c)\n",
    "   \n",
    "    joint=[12,10,9]\n",
    "    a,b,c,M,J = extract_abcM(joint)  #12,10,9\n",
    "    #con5 middle down\n",
    "    con5=curled_finger(a,b,c)\n",
    "        \n",
    "    joint=[8,6,5]\n",
    "    a,b,c,M,J = extract_abcM(joint)   #8,6,5 \n",
    "    #con6 index down   \n",
    "    con6=curled_finger(a,b,c)\n",
    "    \n",
    "    if con3==True and con4==True and con5==True and con6==True:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    " \n",
    "def wrist_vert_r(a,b,c,J,M):\n",
    "    if a[0]< c[0] and  a[2]>c[2]:  #palm facing camera  \n",
    "        radians = abs(np.arctan2((a[0] - J[0]), (J[2]-M[2])))  #(x5-xJ)/(zJ-zM)\n",
    "        j1 = 90+(radians*180.0/np.pi)\n",
    "    elif a[0]>c[0] and a[2]>c[2]:  #palm facing person \n",
    "        radians = (np.arctan2((a[0] - J[0]), (J[2]-M[2])))  #(x5-xJ)/(zJ-zM)\n",
    "        j1 = 90-(radians*180.0/np.pi)\n",
    "    elif a[0]< c[0] and  a[2]<c[2]:\n",
    "        j1=180\n",
    "    elif a[0]>c[0] and a[2]<c[2]:\n",
    "        j1=0\n",
    "    return j1\n",
    "\n",
    "def wrist_vert_l(a,b,c,J,M):\n",
    "    if a[0]< c[0] and  a[2]>c[2]:  #palm facing camera  \n",
    "        radians = abs(np.arctan2((a[0] - J[0]), (J[2]-M[2])))  #(x5-xJ)/(zJ-zM)\n",
    "        j1 = 90-(radians*180.0/np.pi)\n",
    "    elif a[0]>c[0] and a[2]>c[2]:  #palm facing person \n",
    "        radians = (np.arctan2((a[0] - J[0]), (J[2]-M[2])))  #(x5-xJ)/(zJ-zM)\n",
    "        j1 = 90+(radians*180.0/np.pi)\n",
    "    elif a[0]< c[0] and  a[2]<c[2]:\n",
    "        j1=0\n",
    "    elif a[0]>c[0] and a[2]<c[2]:\n",
    "        j1=180\n",
    "    return j1\n",
    "\n",
    "def j2_r(a,b,c,J,M,K):\n",
    "    if M[2]>b[2] and a[0]>c[0] and M[1]>b[1]:   #back down\n",
    "        j2=0\n",
    "    elif M[2]<b[2] and a[0]<c[0] and M[1]>b[1]:   #front down\n",
    "        j2=0\n",
    "    elif M[2]>b[2] and a[0]<c[0] and M[1]>b[1]:  #back up\n",
    "        j2=180\n",
    "    elif M[2]<b[2] and a[0]>c[0] and M[1]>b[1]:  #front  up\n",
    "        j2=180\n",
    "    else:\n",
    "        j2=fold_angle(M,b,K)\n",
    "        \n",
    "    return j2\n",
    "\n",
    "def j2_l(a,b,c,J,M,K):\n",
    "    if M[2]>b[2] and a[0]<c[0] and M[1]>b[1]:  #back down\n",
    "        j2=0\n",
    "    elif M[2]<b[2] and a[0]>c[0] and M[1]>b[1]:  #front down\n",
    "        j2=0\n",
    "    elif M[2]>b[2] and a[0]>c[0] and M[1]>b[1]: #back up\n",
    "        j2=180\n",
    "    elif M[2]<b[2] and a[0]<c[0] and M[1]>b[1]:  #front up\n",
    "        j2=180 \n",
    "    else:\n",
    "        j2=fold_angle(M,b,K)\n",
    "    \n",
    "        \n",
    "    return j2\n",
    "\n",
    "def manual_r(image, results, previousj1, previousj2, previousj3):\n",
    "    #joint 1\n",
    "\n",
    "    joint=[5,0,17]     #5,0,17\n",
    "    a,b,c,M,J= extract_abcM(joint)           #extract abcMJ\n",
    "    text_position = np.array([hand.landmark[joint[1]].x, hand.landmark[joint[1]].y])# position of text , Second coord\n",
    "    j1=wrist_vert_r(a,b,c,J,M)           #calculates joint angle\n",
    "    outputj1,previousj1 = next_angle(j1,previousj1)    #smoothing\n",
    "    render_result(image,str(round(outputj1, 0)),text_position) \n",
    "\n",
    "    #joint 2\n",
    "    joint=[5,0,17] \n",
    "    a,b,c,M,J = extract_abcM(joint)\n",
    "    text_position = np.array([M[0],M[1]])# Second coord\n",
    "    cj1=j1*np.pi/180\n",
    "    K=np.array([b[0]+0.2*np.sin(np.pi-cj1), b[1], 0.2*np.cos(np.pi-cj1)+b[2]])\n",
    "    j2=j2_r(a,b,c,J,M,K)\n",
    "    text_positionk=np.array([K[0],K[1]])\n",
    "    outputj2,previousj2 = next_angle(j2,previousj2) \n",
    "    render_result(image,str(round(outputj2, 0)),text_position)\n",
    "    render_result(image,'K',text_positionk)\n",
    "    \n",
    "    \n",
    "    #joint 3\n",
    "    joint=[12,9,0]\n",
    "    a,b,c,M,J = extract_abcM(joint)\n",
    "    text_position = np.array([hand.landmark[joint[0]].x, hand.landmark[joint[0]].y])\n",
    "    j3=fold_angle(a,b,c)\n",
    "    outputj3,previousj3 = next_angle(j3,previousj3) \n",
    "    render_result(image,str(round(outputj3, 0)),text_position) \n",
    "    \n",
    "    \n",
    "    #sending\n",
    "    outputj1 = round(int(outputj1))\n",
    "    outputj2 = round(int(outputj2))\n",
    "    outputj3 = round(int(outputj3))\n",
    "    #Combine the joint angles into a single message\n",
    "   \n",
    "    return image,outputj1,outputj2,outputj3\n",
    "\n",
    "def manual_l(image, results, livespeed):\n",
    "        \n",
    "    command='none'\n",
    "    #stop\n",
    "    #palm has to face inside (con1)\n",
    "    \n",
    "    joint=[5,0,17]\n",
    "    a,b,c,M,J = extract_abcM(joint)   #5,0,17\n",
    "    text_position_j1= np.array([hand.landmark[joint[1]].x, hand.landmark[joint[1]].y])# Second coord\n",
    "    j1=wrist_vert_l(a,b,c,J,M)\n",
    "    render_result(image,str(round(j1, 0)),text_position_j1) \n",
    "\n",
    "    #con2 palm upright\n",
    "    joint=[5,0,17]\n",
    "    a,b,c,M,J = extract_abcM(joint)   #5,0,17\n",
    "    text_position = np.array([M[0],M[1]])\n",
    "    cj1=j1*np.pi/180\n",
    "    K=np.array([b[0]-0.2*np.sin(np.pi-cj1), b[1], b[2]+0.2*np.cos(np.pi-cj1)])\n",
    "    j2=j2_l(a,b,c,J,M,K)\n",
    "    text_positionk=np.array([K[0],K[1]])\n",
    "    render_result(image,str(round(j2, 0)),text_position)\n",
    "    render_result(image,'K',text_positionk)\n",
    "    \n",
    "    #check fingers curled\n",
    "    check_fingers_curled=fingers_curled()\n",
    "    check_fingers_straight=fingers_straight()\n",
    "    \n",
    "    if 60<j1<120 and 60<j2<120 and check_fingers_curled==True:\n",
    "        #render the result on the image\n",
    "        command='stop'\n",
    "        render_result(image,'stop',text_position_j1)\n",
    "        \n",
    "    joint=[12,9,0]\n",
    "    a,b,c,M,J = extract_abcM(joint)  #12,9,0\n",
    "    text_position = np.array([hand.landmark[joint[0]].x, hand.landmark[joint[0]].y])\n",
    "    j3=fold_angle(a,b,c)\n",
    "    render_result(image,str(round(j3, 0)),text_position)\n",
    "    \n",
    "    if j1<20 and j2>160 and check_fingers_curled==True:\n",
    "        command='turn left'\n",
    "    if j1>160 and j2<50 and check_fingers_curled==True:\n",
    "        command='turn right'\n",
    "    \n",
    "        \n",
    "    if j1<30 and 70<j2<150 and j3<40:\n",
    "        command='rev'\n",
    "        render_result(image,'rev',text_position) \n",
    "    elif j1>160 and 75<j2<120 and 30<j3<90 and a[2]<c[2]:\n",
    "        command='forward'\n",
    "        render_result(image,'forward',text_position) \n",
    "    if command=='rev' or command=='stop' or command=='forward' or command=='turn left' or command=='turn right' or command=='left' or command=='right':\n",
    "        hi='hi'\n",
    "    else:\n",
    "        command = 'nothing'\n",
    "        \n",
    "    return image,command\n",
    "\n",
    "def come_follow(image,results, text, counter, hand, menu, grab):\n",
    "    \n",
    "    command='none'     #value for first reference\n",
    "    j1=0\n",
    "    j2=0\n",
    "    j3=0\n",
    "\n",
    "        \n",
    "    if text[0]=='R':\n",
    "        joint=[5,0,17]    #5,0,17\n",
    "        a,b,c,M,J = extract_abcM(joint)\n",
    "        text_position_j1 = np.array([hand.landmark[joint[1]].x, hand.landmark[joint[1]].y])# position of text , Second coord\n",
    "        j1=wrist_vert_r(a,b,c,J,M)\n",
    "        render_result(image,str(round(j1, 0)),text_position_j1)\n",
    "        center_coordinatex=int(round((a[0]+b[0]+c[0])/3*640,0))\n",
    "        center_coordinatey=int(round((a[1]+b[1]+c[1])/3*480,0))\n",
    "        \n",
    "        \n",
    "        joint=[5,0,17] \n",
    "        a,b,c,M,J = extract_abcM(joint)\n",
    "        text_position = np.array([M[0],M[1]])# Second coord\n",
    "        K = np.array([M[0], b[1], M[2]]) # K coord\n",
    "        j2=j2_r(a,b,c,J,M,K)\n",
    "        render_result(image,str(round(j2, 0)),text_position)\n",
    "        \n",
    "        #check fingers curled/straight\n",
    "        check_fingers_curled=fingers_curled()\n",
    "        check_fingers_straight=fingers_straight()\n",
    "        \n",
    "        if 60<j1<120 and 60<j2<120 and check_fingers_curled==True:\n",
    "            #render the result on the image\n",
    "            command='stop'\n",
    "            render_result(image,'stop',text_position_j1)\n",
    "            grab=False\n",
    "        \n",
    "        joint=[12,9,0]\n",
    "        a,b,c,M,J = extract_abcM(joint)\n",
    "        text_position = np.array([hand.landmark[joint[0]].x, hand.landmark[joint[0]].y])\n",
    "        j3=fold_angle(a,b,c)\n",
    "        render_result(image,str(round(j3, 0)),text_position)\n",
    "        \n",
    "        \n",
    "        if j1<30 and 70<j2<110 and check_fingers_straight==True:\n",
    "            menu=True\n",
    "        \n",
    "        if menu==True:\n",
    "            if j2<70 or j2>110 or j1>30:\n",
    "                menu=False\n",
    "                \n",
    "        if menu==True:\n",
    "            cv2.circle(image,(center_coordinatex,center_coordinatey), 20, (0,255,255), -1)\n",
    "            if j1<30 and 70<j2<110 and check_fingers_curled==True:\n",
    "                grab=True\n",
    "                \n",
    "        if grab==True:\n",
    "            cv2.circle(image,(center_coordinatex,center_coordinatey), 20, (255,0,255), -1)\n",
    "       # if grab==True:\n",
    "            #check_fingers_straight=fingers_straight()\n",
    "           # if check_fingers_straight==True:\n",
    "              #  grab=False\n",
    "                \n",
    "                \n",
    "    elif text[0]=='L':\n",
    "        joint=[5,0,17]\n",
    "        a,b,c,M,J = extract_abcM(joint)   #5,0,17\n",
    "        text_position_j1 = np.array([hand.landmark[joint[1]].x, hand.landmark[joint[1]].y])# Second coord\n",
    "        j1=wrist_vert_l(a,b,c,J,M)\n",
    "        render_result(image,str(round(j1, 0)),text_position_j1)\n",
    "        center_coordinatex=int(round((a[0]+b[0]+c[0])/3*640,0))\n",
    "        center_coordinatey=int(round((a[1]+b[1]+c[1])/3*480,0))\n",
    "        \n",
    "        joint=[5,0,17]\n",
    "        a,b,c,M,J = extract_abcM(joint)\n",
    "        text_position = np.array([M[0],M[1]])# Second coord\n",
    "        K = np.array([M[0], b[1], M[2]]) # K coord\n",
    "        j2=j2_l(a,b,c,J,M,K) \n",
    "        render_result(image,str(round(j2, 0)),text_position)\n",
    "        \n",
    "        #stop\n",
    "        check_fingers_curled=fingers_curled()\n",
    "        check_fingers_straight=fingers_straight()\n",
    "        \n",
    "        if 60<j1<120 and 60<j2<120 and check_fingers_curled==True:\n",
    "            #render the result on the image\n",
    "            command='stop'\n",
    "            render_result(image,'stop',text_position_j1) \n",
    "            grab=False\n",
    "         \n",
    "        joint=[12,9,0]\n",
    "        a,b,c,M,J = extract_abcM(joint)\n",
    "        text_position = np.array([hand.landmark[joint[0]].x, hand.landmark[joint[0]].y])\n",
    "        j3=fold_angle(a,b,c)\n",
    "        #render the result on the image\n",
    "        render_result(image,str(round(j3, 0)),text_position)\n",
    "        \n",
    "        if j1<30 and 70<j2<110 and check_fingers_straight==True:\n",
    "            menu=True\n",
    "            \n",
    "        if menu==True:\n",
    "            if j2<70 or j2>110 or j1>30:\n",
    "                menu=False\n",
    "        if menu==True:\n",
    "            cv2.circle(image,(center_coordinatex,center_coordinatey), 20, (0,255,255), -1)\n",
    "            if j1<30 and 70<j2<110 and check_fingers_curled==True:\n",
    "                grab=True\n",
    "        \n",
    "        if grab==True:\n",
    "            cv2.circle(image,(center_coordinatex,center_coordinatey), 20, (255,0,255), -1)\n",
    "            \n",
    "        #if grab==True:\n",
    "           # check_fingers_straight=fingers_straight()\n",
    "            #if check_fingers_straight==True:\n",
    "              #  grab=False\n",
    "                \n",
    "                \n",
    "    #check command\n",
    "    if j1>150 and 70<j2<110 and j3<28:     #hand in frame, come/follow\n",
    "        if abs(a[0] - c[0])< abs(a[1] - c[1]):\n",
    "            d1= abs(a[1] - c[1])\n",
    "        elif  abs(a[0] - c[0])> abs(a[1] - c[1]):\n",
    "            d1= abs(a[0] - c[0])\n",
    "        #print(d1)\n",
    "        #turn the direction\n",
    "        if d1>0.5 :\n",
    "            command='stop'\n",
    "            render_result(image,'    too close, stop',text_position)\n",
    "        elif b[0]>0.55:\n",
    "            #turnright\n",
    "            command='turn right'\n",
    "            render_result(image,'    turn right,come',text_position)\n",
    "        elif b[0]<0.45:\n",
    "        #turn left\n",
    "            command='turn left'\n",
    "            render_result(image,'    turn left,come',text_position)\n",
    "        elif 0.47<b[0]<0.53:\n",
    "            #stop\n",
    "            command='forward'                               #needs verification!!!!!!!!!!\n",
    "            render_result(image,'    come',text_position)\n",
    "        \n",
    "    # option follow landmark\n",
    "    \n",
    "        \n",
    "    if command=='follow':   #hand not in frame, holistic landmark (command registered)\n",
    "        hi='hi'\n",
    "        \n",
    "    if command=='rev' or command=='stop' or command=='turn right' or command=='turn left' or command=='forward':\n",
    "        hi='hi'\n",
    "    else:\n",
    "        command='nothing'\n",
    "        \n",
    "    return image, command, counter, menu, grab\n",
    "\n",
    "def driving(command,livespeed,cpd,spd,ppd,tpd,mode):\n",
    "\n",
    "    if command=='rev':\n",
    "        circle_dir, square_dir,plus_dir,triangle_dir = 0,1,2,2\n",
    "        livespeed=50\n",
    "        cpd,spd,ppd,tpd=0,1,2,2\n",
    "            \n",
    "    elif command=='forward':\n",
    "        circle_dir, square_dir,plus_dir,triangle_dir =  1,0,2,2\n",
    "        livespeed=30\n",
    "        cpd,spd,ppd,tpd=1,0,2,2\n",
    "        \n",
    "    elif command=='stop':\n",
    "        circle_dir,square_dir,plus_dir, triangle_dir  = 2,2,2,2\n",
    "        livespeed=0\n",
    "        cpd,spd,ppd,tpd = 2,2,2,2\n",
    "        \n",
    "    elif command=='turn right':\n",
    "        circle_dir,square_dir,plus_dir,triangle_dir= 1,1,1,1        \n",
    "        livespeed=20\n",
    "        cpd,spd,ppd,tpd=1,1,1,1\n",
    "        \n",
    "    elif command=='turn left':\n",
    "        circle_dir,square_dir,plus_dir,triangle_dir  = 0,0,0,0        \n",
    "        livespeed=20\n",
    "        cpd,spd,ppd,tpd=0,0,0,0\n",
    "        \n",
    "    elif command=='left':\n",
    "        circle_dir,square_dir,plus_dir,triangle_dir = 2,2,0,1        \n",
    "        livespeed=25\n",
    "        cpd,spd,ppd,tpd=2,2,0,1\n",
    "    \n",
    "    elif command=='right':\n",
    "        circle_dir,square_dir,plus_dir,triangle_dir = 2,2,1,0        \n",
    "        livespeed=25\n",
    "        cpd,spd,ppd,tpd=2,2,1,0\n",
    "        \n",
    "    elif command=='nothing':\n",
    "        if mode=='manual':\n",
    "            if livespeed!=0:\n",
    "                livespeed=livespeed-1\n",
    "                \n",
    "                circle_dir, circle_speed =  cpd, livespeed\n",
    "                square_dir, square_speed =  spd, livespeed\n",
    "                plus_dir, plus_speed =  ppd, 0\n",
    "                triangle_dir, triangle_speed = tpd, 0\n",
    "                \n",
    "            else:\n",
    "                circle_dir, square_dir,plus_dir, triangle_dir = cpd, spd, ppd, tpd\n",
    "\n",
    "        elif mode=='default':\n",
    "            #add check complete\n",
    "             circle_dir, square_dir,plus_dir,triangle_dir = cpd,spd,ppd,tpd\n",
    "\n",
    "        \n",
    "    return (livespeed, cpd, spd, ppd, tpd,\n",
    "            circle_dir,square_dir,plus_dir, triangle_dir)\n",
    "\n",
    "def option_Menu():\n",
    "    canvas=255* np.ones((640,480, 3), dtype=np.uint8)\n",
    "    options= ['1. Manual mode', '2. Default mode', '3. YOLO', 'Q. Quit']\n",
    "    for i, option in enumerate(options):\n",
    "        cv2.putText(canvas, option, (50, 50+50*i), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "    \n",
    "    cv2.imshow('Menu', canvas)\n",
    "    key=cv2.waitKey(0)\n",
    "    \n",
    "    if key== ord('1'):\n",
    "        print('Selected manual mode')\n",
    "        mode='manual'\n",
    "        \n",
    "        canvas.fill(255)\n",
    "        submenu_options = ['Q. Quit']\n",
    "        \n",
    "        for i, option in enumerate(submenu_options):\n",
    "            cv2.putText(canvas, option, (50,50+50*i), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "    \n",
    "        cv2.imshow('Menu', canvas)\n",
    "        \n",
    "        \n",
    "    elif key== ord('2'):\n",
    "        print('Selected default mode')\n",
    "        mode='default'\n",
    "        \n",
    "        canvas.fill(255)\n",
    "        submenu_options = ['Q. Quit']\n",
    "        \n",
    "        for i, option in enumerate(submenu_options):\n",
    "            cv2.putText(canvas, option, (50,50+50*i), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "    \n",
    "        cv2.imshow('Menu', canvas)\n",
    "    \n",
    "    elif key== ord('3'):\n",
    "        print('Selected YOLO')\n",
    "        canvas.fill(255)\n",
    "        yolo_options = ['1. can', '2. orange', '3. mouse', 'Q. Quit']\n",
    "        \n",
    "        for i, option in enumerate(yolo_options):\n",
    "            cv2.putText(canvas, option, (50,50+50*i), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "    \n",
    "        cv2.imshow('Menu', canvas)\n",
    "        key_yolo = cv2.waitKey(0)\n",
    "        \n",
    "        if key_yolo == ord('1'):\n",
    "            print('Selected can')\n",
    "            mode = 'can'\n",
    "        elif key_yolo == ord('2'):\n",
    "            print('Selected orange')\n",
    "            mode = 'orange'\n",
    "        elif key_yolo == ord('3'):\n",
    "            print('Selected mouse')\n",
    "            mode = 'mouse'\n",
    "        elif key_yolo == ord('q'):\n",
    "            print('Quitting')\n",
    "            mode = 'quit'\n",
    "        else:\n",
    "            print('wrong input')\n",
    "            mode = 'quit'\n",
    "        \n",
    "    elif key== ord('q'):\n",
    "        print('Quitting')\n",
    "        mode='quit'\n",
    "        \n",
    "    else:\n",
    "        print('wrong input')\n",
    "        mode=='quit'\n",
    "        \n",
    "    return mode\n",
    "\n",
    "\n",
    "def person_tracking(width_p,height_p, sending, recenter, centroid_x, centroid_y, livespeed, cpd, spd, ppd, tpd, mode, previousj1, previousj2, previousj3,previousj4): \n",
    "    reached=False\n",
    "    if recenter!=True:\n",
    "    #x control (base)\n",
    "        if centroid_x>340:\n",
    "            command='turn right'\n",
    "            (livespeed,cpd,spd,ppd,tpd,\n",
    "            circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)\n",
    "            print(command)\n",
    "            #send instruction\n",
    "            bigmode=1\n",
    "            if sending==True:\n",
    "                pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "        elif centroid_x<300:\n",
    "            command='turn left'\n",
    "            (livespeed,cpd,spd,ppd,tpd,\n",
    "            circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)\n",
    "            print(command)\n",
    "            #send instruction\n",
    "            bigmode=1\n",
    "            if sending==True:\n",
    "                pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "        elif 300 < centroid_x < 340 and (width_p>=300 and height_p>=160):\n",
    "            command='stop'\n",
    "            (livespeed,cpd,spd,ppd,tpd,\n",
    "            circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)\n",
    "            print(command, 'approached person')\n",
    "            #send instruction\n",
    "            bigmode=1\n",
    "            reached=True\n",
    "            if sending==True:\n",
    "                pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "    \n",
    "        elif 300 <= centroid_x <= 340 and (width_p<=300 and height_p<=160):\n",
    "            command='forward'\n",
    "            (livespeed,cpd,spd,ppd,tpd,\n",
    "            circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)\n",
    "            print(command, 'found, approaching...')\n",
    "            #send instruction\n",
    "            bigmode=1\n",
    "\n",
    "            if sending==True:\n",
    "                pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "                \n",
    "    elif recenter==True:\n",
    "        bigmode=0\n",
    "        #y control (arm)\n",
    "        if centroid_y>300: #lowerframe\n",
    "            previousj2=previousj2-1   #move cam down\n",
    "            print(previousj2)\n",
    "\n",
    "            if sending==True:\n",
    "                pass_instruction_arm(bigmode, previousj1, previousj2, previousj3,previousj4, livespeed)     \n",
    "        \n",
    "        elif centroid_y<180: #upperframe\n",
    "            if previousj2>=120:\n",
    "                previousj3=previousj3-1  #move cam up\n",
    "\n",
    "                if sending==True:\n",
    "                    pass_instruction_arm(bigmode, previousj1, previousj2, previousj3,previousj4, livespeed)\n",
    "            \n",
    "            elif previousj2<120:\n",
    "                previousj2=previousj2+1  # move cam up\n",
    "                print(previousj2)\n",
    "\n",
    "                if sending==True:\n",
    "                    pass_instruction_arm(bigmode, previousj1, previousj2, previousj3,previousj4, livespeed)\n",
    "                    \n",
    "\n",
    "    return reached, previousj2, previousj3\n",
    "    \n",
    "def object_tracking(sending, recenter, centroid_x, livespeed, cpd, spd, ppd, tpd, mode, previousj1, previousj2, previousj3,previousj4, Ywid, Yheit): \n",
    "    reached=False\n",
    "    if recenter!=True:\n",
    "    #x control (base)\n",
    "        if centroid_x>340:\n",
    "            command='turn right'\n",
    "            (livespeed,cpd,spd,ppd,tpd,\n",
    "            circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)\n",
    "            print(command)\n",
    "            #send instruction\n",
    "            bigmode=1\n",
    "            if sending==True:\n",
    "                pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "        elif centroid_x<300:\n",
    "            command='turn left'\n",
    "            (livespeed,cpd,spd,ppd,tpd,\n",
    "            circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)\n",
    "            print(command)\n",
    "            #send instruction\n",
    "            bigmode=1\n",
    "            if sending==True:\n",
    "                pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "        elif 300 < centroid_x < 340 and (width>=Ywid and height>=Yheit):\n",
    "            command='stop'\n",
    "            (livespeed,cpd,spd,ppd,tpd,\n",
    "            circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)\n",
    "            print(command, 'approached object')\n",
    "            #send instruction\n",
    "            bigmode=1\n",
    "            reached=True\n",
    "            if sending==True:\n",
    "                pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "    \n",
    "        elif 300 <= centroid_x <= 340 and (width<=Ywid and height<=Yheit):\n",
    "            command='forward'\n",
    "            (livespeed,cpd,spd,ppd,tpd,\n",
    "            circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)\n",
    "            print(command, 'found, approaching...')\n",
    "            #send instruction\n",
    "            bigmode=1\n",
    "\n",
    "            if sending==True:\n",
    "                pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "                \n",
    "    elif recenter==True:\n",
    "        bigmode=0\n",
    "        #y control (arm)\n",
    "        if centroid_y>260: #lowerframe\n",
    "            previousj2=previousj2-1   #move cam down\n",
    "            print(previousj2)\n",
    "\n",
    "            if sending==True:\n",
    "                pass_instruction_arm(bigmode, previousj1, previousj2, previousj3,previousj4, livespeed)     \n",
    "        \n",
    "        elif centroid_y<220: #upperframe\n",
    "            if previousj2>=120:\n",
    "                previousj3=previousj3-1  #move cam up\n",
    "\n",
    "                if sending==True:\n",
    "                    pass_instruction_arm(bigmode, previousj1, previousj2, previousj3,previousj4, livespeed)\n",
    "            \n",
    "            elif previousj2<120:\n",
    "                previousj2=previousj2+1  # move cam up\n",
    "                print(previousj2)\n",
    "\n",
    "                if sending==True:\n",
    "                    pass_instruction_arm(bigmode, previousj1, previousj2, previousj3,previousj4, livespeed)\n",
    "                    \n",
    "\n",
    "    return reached, previousj2, previousj3\n",
    "    \n",
    "condition='0'  \n",
    "#mode\n",
    "mode='nothing'\n",
    "#run\n",
    "run=True\n",
    "\n",
    "previousj1,previousj2,previousj3,previousj4=90,125,150,90\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while run==True:\n",
    "    \n",
    "    \n",
    "    #setup\n",
    "    command='nothing'\n",
    "    livespeed = 0\n",
    "    cpd,spd,ppd,tpd=2,2,2,2\n",
    "    circle_dir,square_dir,triangle_dir,plus_dir=2,2,2,2\n",
    "    menu,grab, havehandr,havehandl=False, False, False, False\n",
    "    dl,dr=0,0\n",
    "    condition='0' \n",
    "    \n",
    "    \n",
    "   \n",
    "    if voice_override==True:\n",
    "        mode=transcribe_microphone()\n",
    "        print('mode: ', mode)\n",
    "    else:\n",
    "        mode=option_Menu()\n",
    "        \n",
    "    \n",
    "    if mode=='default' or mode=='can' or mode=='mouse' or mode=='orange':\n",
    "        #url='http://172.20.10.3:81/stream'#new code\n",
    "        cap = cv2.VideoCapture(0)#new code\n",
    "        #cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():#new code\n",
    "            print('failed to open IP camera')\n",
    "            exit()\n",
    "\n",
    "    if mode=='manual':\n",
    "        url='http://172.20.10.3:81/stream'#new code\n",
    "        cap = cv2.VideoCapture(url)\n",
    "        #cap=cv2.VideoCapture(0)\n",
    "        \n",
    "        with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.3) as hands:\n",
    "\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()         \n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  #bgr2rgb\n",
    "                image = cv2.flip(image, 1)              #flip\n",
    "                image.flags.writeable = False           # Set flag\n",
    "                results = hands.process(image)         # Detections\n",
    "                image.flags.writeable = True             # Set flag to true\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)   #rgb 2 bgr\n",
    "                \n",
    "                # Rendering results\n",
    "                if results.multi_hand_landmarks:  # if any result\n",
    "                    for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                        mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=1),\n",
    "                                                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=1),)\n",
    "                        \n",
    "                \n",
    "                        # Render left or right detection\n",
    "                        if get_label(num, hand, results):\n",
    "                            text, coord = get_label(num, hand, results)\n",
    "                            cv2.putText(image, text, coord, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                            if text[0]=='R':\n",
    "                                image,previousj1,previousj2,previousj3 = manual_r(image, results,previousj1,previousj2,previousj3)\n",
    "                                \n",
    "                                joint=[5,0,17]\n",
    "                                a,b,c,M,J = extract_abcM(joint)\n",
    "                                d517=np.linalg.norm(a - c)\n",
    "                                dM17=np.linalg.norm(M - b)\n",
    "                                if d517< dM17:\n",
    "                                    dr= dM17\n",
    "                                elif  d517> dM17:\n",
    "                                    dr= d517\n",
    "                                center_coordinatexr=int(round((a[0]+b[0]+c[0])/3*640,0))\n",
    "                                center_coordinateyr=int(round((a[1]+b[1]+c[1])/3*480,0))\n",
    "                                havehandr=True\n",
    "                                \n",
    "                            if text[0]=='L':\n",
    "                                image,command = manual_l(image, results, command)\n",
    "                            \n",
    "                                joint=[5,0,17]\n",
    "                                a,b,c,M,J = extract_abcM(joint)\n",
    "                                d517=np.linalg.norm(a - c)\n",
    "                                dM17=np.linalg.norm(M - b)\n",
    "                                if d517< dM17:\n",
    "                                    dl= dM17\n",
    "                                elif  d517> dM17:\n",
    "                                    dl= d517\n",
    "                                center_coordinatexl=int(round((a[0]+b[0]+c[0])/3*640,0))\n",
    "                                center_coordinateyl=int(round((a[1]+b[1]+c[1])/3*480,0))\n",
    "                                havehandl=True\n",
    "                                \n",
    "                            #print('dr:',dr,'dl:',dl)\n",
    "                            \n",
    "                else:\n",
    "                    \n",
    "                    command='nothing'\n",
    "\n",
    "            \n",
    "                #identify speed/direction     \n",
    "                (livespeed,cpd,spd,ppd,tpd,\n",
    "                circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)\n",
    "\n",
    "                #send instruction\n",
    "                \n",
    "                \n",
    "                if  havehandr==True and havehandl==True and dr>dl:\n",
    "                    bigmode=0\n",
    "                    cv2.circle(image,(center_coordinatexr,center_coordinateyr), 10, (255,0,255), -1)\n",
    "                    \n",
    "                    if dl!=0:\n",
    "                        cv2.circle(image,(100,200), 10, (255,255,255), -1)\n",
    "                        cv2.circle(image,(200,200), 10, (0,0,0), -1) \n",
    "                    if dl!=0 and 80<center_coordinatexl<120 and 180<center_coordinateyl<220:\n",
    "                        previousj4=60\n",
    "                    elif dl!=0 and 180<center_coordinatexl<220 and 180<center_coordinateyl<220:\n",
    "                        previousj4=180 \n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3,previousj4, livespeed) \n",
    "                        \n",
    "                    havehandr,havehandl=False,False\n",
    "                    \n",
    "                elif  havehandl==True and havehandr==True and dl>dr:\n",
    "                    bigmode=1\n",
    "                    cv2.circle(image,(center_coordinatexl,center_coordinateyl), 10, (255,0,255), -1)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir,triangle_dir, livespeed)\n",
    "                    \n",
    "                    havehandr,havehandl=False,False\n",
    "                    \n",
    "                elif havehandr==True and havehandl==False:\n",
    "                    dl=0\n",
    "                    bigmode=0\n",
    "                    cv2.circle(image,(center_coordinatexr,center_coordinateyr), 10, (255,0,255), -1)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3,previousj4, livespeed)\n",
    "                    \n",
    "                    havehandr=False\n",
    "                    \n",
    "                elif havehandr==False and havehandl==True:\n",
    "                    dr=0\n",
    "                    bigmode=1\n",
    "                    cv2.circle(image,(center_coordinatexl,center_coordinateyl), 10, (255,0,255), -1)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir,triangle_dir, livespeed)\n",
    "                    \n",
    "                    havehandl=False\n",
    "                \n",
    "                cv2.namedWindow('manual control',cv2.WINDOW_NORMAL)\n",
    "                cv2.resizeWindow('manual control',640,480)\n",
    "                cv2.setWindowProperty('manual control',cv2.WND_PROP_TOPMOST, 1)\n",
    "                cv2.imshow('manual control', image)\n",
    "\n",
    "                \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                # port1.close()\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "        cap.release()\n",
    "        cv2.destroyWindow('manual control')\n",
    "\n",
    "\n",
    "    elif mode=='default':   #come/folllow\n",
    "        text='None'\n",
    "        counter=0\n",
    "        bigmode=0\n",
    "        j2,j3=120,110\n",
    "        while previousj2!=j2 and previousj3!=j3:\n",
    "            if previousj2<j2:\n",
    "                previousj2+=2\n",
    "            elif previousj2>j2:\n",
    "                previousj2-=2\n",
    "            if previousj3<j3:\n",
    "                previousj3+=2\n",
    "            elif previousj3>j3:\n",
    "                previousj3-=2\n",
    "            print (previousj2,previousj3)\n",
    "            if sending==True:\n",
    "                pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "                delay_time = 0.05  # 0.05 s delay\n",
    "\n",
    "                # Sleep for the specified delay time\n",
    "                time.sleep(delay_time)\n",
    "                \n",
    "            \n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.7, min_tracking_confidence=0.85) as holistic:\n",
    "            #url='http://172.20.10.3:81/stream'#new code\n",
    "           # cap = cv2.VideoCapture(url)#new code\n",
    "            while cap.isOpened():\n",
    "                recenter=False\n",
    "                reached=False\n",
    "                ret, frame = cap.read()\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  #bgr2rgb\n",
    "                image.flags.writeable = False           # Set flag\n",
    "                results=holistic.process(image)\n",
    "                image.flags.writeable = True             # Set flag to true\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)   #rgb 2 bgr\n",
    "                image=cv2.resize(image,(640,480))\n",
    "\n",
    "                if results.pose_landmarks:\n",
    "                    pose=results.pose_landmarks\n",
    "                    mp_drawing.draw_landmarks(image, pose, mp_holistic.POSE_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(247, 0, 255), thickness=2, circle_radius=1),\n",
    "                                            mp_drawing.DrawingSpec(color=(255, 230, 0), thickness=2, circle_radius=1),)\n",
    "                    \n",
    "\n",
    "                if results.right_hand_landmarks:  # right hand\n",
    "                    hand=results.right_hand_landmarks\n",
    "                    mp_drawing.draw_landmarks(image, hand, mp_holistic.HAND_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=1),\n",
    "                                            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=1),)\n",
    "                    joint=[12,9,0]\n",
    "                    a,b,c,M,J = extract_abcM(joint)\n",
    "                    if abs(a[0] - c[0])< abs(a[1] - c[1]):\n",
    "                        dr= abs(a[1] - c[1])\n",
    "                    elif  abs(a[0] - c[0])> abs(a[1] - c[1]):\n",
    "                        dr= abs(a[0] - c[0])\n",
    "                    \n",
    "                    \n",
    "                if results.left_hand_landmarks:   # left hand\n",
    "                    hand=results.left_hand_landmarks\n",
    "                    mp_drawing.draw_landmarks(image, hand, mp_holistic.HAND_CONNECTIONS, \n",
    "                                                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=1),\n",
    "                                                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=1),)\n",
    "                    joint=[12,9,0]\n",
    "                    a,b,c,M,J = extract_abcM(joint)\n",
    "                    if abs(a[0] - c[0])< abs(a[1] - c[1]):\n",
    "                        dl= abs(a[1] - c[1])\n",
    "                    elif  abs(a[0] - c[0])> abs(a[1] - c[1]):\n",
    "                        dl= abs(a[0] - c[0])\n",
    "\n",
    "                if results.right_hand_landmarks and results.left_hand_landmarks:\n",
    "                    if dl<dr:\n",
    "                        text='Right'\n",
    "                        hand=results.right_hand_landmarks\n",
    "                    elif dr<dl:\n",
    "                        text='Left'\n",
    "                        hand=results.left_hand_landmarks\n",
    "                    image, command, counter, menu, grab = come_follow(image, results, text, counter, hand, menu, grab)\n",
    "                elif results.left_hand_landmarks:\n",
    "                    text='Left'\n",
    "                    hand=results.left_hand_landmarks\n",
    "                    image, command, counter, menu, grab = come_follow(image, results, text, counter, hand, menu, grab)\n",
    "                elif results.right_hand_landmarks:\n",
    "                    text='Right'\n",
    "                    hand=results.right_hand_landmarks\n",
    "                    image, command, counter, menu, grab = come_follow(image, results, text, counter, hand, menu, grab)  \n",
    "                    \n",
    "                else:\n",
    "                    command=='nothing'\n",
    "\n",
    "                \n",
    "                #new part\n",
    "                if command=='stop':\n",
    "                    stopcounter+=1\n",
    "                elif command!='stop':\n",
    "                    stopcounter=0\n",
    "                print('stopcounter:', stopcounter)\n",
    "                #end of new part\n",
    "\n",
    "                \n",
    "                if grab==True and results.pose_landmarks:\n",
    "                    joint=[12,10,11]\n",
    "                    M=np.array([(pose.landmark[joint[0]].x + pose.landmark[joint[2]].x)/2, (pose.landmark[joint[0]].y + pose.landmark[joint[2]].y)/2])\n",
    "                    M_x=int(round(M[0]*640,0))\n",
    "                    M_y=int(round(M[1]*480,0))\n",
    "                    width_p=int(round(abs(pose.landmark[joint[0]].x-pose.landmark[joint[2]].x)*640,0))\n",
    "                    height_p=int(round(abs(pose.landmark[joint[0]].y-pose.landmark[joint[1]].y)*480,0))\n",
    "                    cv2.circle(image,(M_x,M_y), 20, (0,0,255), -1)\n",
    "                    if M_y>300 or M_y<160: #if centroid y should be adjusted:\n",
    "                        recenter=True\n",
    "                    reached, previousj2, previousj3=person_tracking(width_p,height_p, sending, recenter, M_x,M_y, livespeed, cpd, spd, ppd, tpd, mode, previousj1, previousj2, previousj3,previousj4)\n",
    "                    print(width_p,height_p)\n",
    "                        \n",
    "                    #if reached==True:\n",
    "                        #print('reached')\n",
    "                        #break  \n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    (livespeed,cpd,spd,ppd,tpd,\n",
    "                    circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)\n",
    "                    #print(command)\n",
    "                    #send instruction\n",
    "                    bigmode=1\n",
    "                    if sending==True:\n",
    "                        pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "                \n",
    "                cv2.namedWindow('default mode',cv2.WINDOW_NORMAL)\n",
    "                cv2.resizeWindow('default mode',640,480)\n",
    "                cv2.setWindowProperty('default mode',cv2.WND_PROP_TOPMOST, 1)\n",
    "                cv2.imshow('default mode', image)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q') or stopcounter>=30:\n",
    "                # port1.close()\n",
    "\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "        cap.release()\n",
    "        cv2.destroyWindow('default mode')\n",
    "\n",
    "        \n",
    "        \n",
    "    if mode=='mouse': \n",
    "        stopcounter=0\n",
    "        specific_class='mouse'\n",
    "        model=default_model\n",
    "        Yj2 = 0\n",
    "        Yj3 = 45\n",
    "        Yj4_l = 160\n",
    "        Yj4_s = 100\n",
    "        Ywid = 170\n",
    "        Yheit = 220\n",
    "        min_distance_threshold = 10\n",
    "        reached=False\n",
    "        grabbed=False\n",
    "        put_box=False\n",
    "        dropped=False\n",
    "        while cap.isOpened():\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            results= model(frame)\n",
    "            boxes = results.xyxy[0].cpu().numpy()  # Convert to numpy array      \n",
    "            class_to_priority = {} \n",
    "            recenter = False\n",
    "            priority_mouse_present = False\n",
    "            \n",
    "            if reached==False:\n",
    "                \n",
    "                for box in boxes:\n",
    "                    class_id = int(box[5])  # Extract class ID\n",
    "                    class_name = model.names[class_id]  # Convert class ID to class name\n",
    "                    confidence = box[4]\n",
    "\n",
    "                    if class_name == specific_class:\n",
    "                        centroid_x = (box[0] + box[2]) // 2  # Calculate centroid x-coordinate\n",
    "                        centroid_y = (box[1] + box[3]) // 2  # Calculate centroid y-coordinate\n",
    "                         # Check if the specific class is already assigned a priority\n",
    "                        if specific_class not in class_to_priority:\n",
    "                            # If not, assign the current object as the priority\n",
    "                            class_to_priority[specific_class] = {'centroid': (centroid_x, centroid_y), 'confidence': confidence}\n",
    "                        else:\n",
    "                            # If yes, compare the confidence with the current object\n",
    "                            if confidence > class_to_priority[specific_class]['confidence']:\n",
    "                                # If current object has higher confidence, update priority\n",
    "                                class_to_priority[specific_class] = {'centroid': (centroid_x, centroid_y), 'confidence': confidence}\n",
    "                        if (centroid_x, centroid_y) == class_to_priority[specific_class]['centroid']:\n",
    "                            priority_mouse_present = True\n",
    "\n",
    "                for box in boxes:\n",
    "                    class_id = int(box[5])  # Extract class ID\n",
    "                    class_name = model.names[class_id]  # Convert class ID to class name\n",
    "                    confidence = box[4]  # Extract confidence score\n",
    "                    x1, y1, x2, y2 = box[:4].astype(int)\n",
    "                    centroid_x = (x1 + x2) // 2\n",
    "                    centroid_y = (y1 + y2) // 2\n",
    "                    width = x2 - x1\n",
    "                    height = y2 - y1\n",
    "\n",
    "                    if class_name == specific_class:\n",
    "                        # Check if the priority mouse is present in the current frame\n",
    "                        if priority_mouse_present:\n",
    "                            # If the priority mouse is present, mark it as red\n",
    "                            if (centroid_x, centroid_y) == class_to_priority[specific_class]['centroid']:\n",
    "                                cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 0, 255), -1)\n",
    "                                print(f\"Centroid position: ({centroid_x}, {centroid_y}, {width}, {height})\")\n",
    "\n",
    "                                if centroid_y>300 or centroid_y<160: #if centroid y should be adjusted:\n",
    "                                    recenter=True\n",
    "                                reached, previousj2, previousj3 =object_tracking(sending, recenter, centroid_x, livespeed, cpd, spd, ppd, tpd, mode, previousj1, previousj2, previousj3,previousj4, Ywid, Yheit)\n",
    "                                if reached==True:\n",
    "                                    print('reached')\n",
    "                                    break  \n",
    "                            else:\n",
    "                                # Check if the distance between centroids is below the threshold\n",
    "                                priority_centroid_x, priority_centroid_y = class_to_priority[specific_class]['centroid']\n",
    "                                distance = np.sqrt((centroid_x - priority_centroid_x) ** 2 + (centroid_y - priority_centroid_y) ** 2)\n",
    "                                if distance < min_distance_threshold:\n",
    "                                    cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 0, 255), -1)  # Draw as red\n",
    "                                    print(f\"Centroid position: ({centroid_x}, {centroid_y})\")\n",
    "\n",
    "                                    if centroid_y>300 or centroid_y<160: #if centroid y should be adjusted:\n",
    "                                        recenter=True\n",
    "\n",
    "                                    reached, previousj2, previousj3=object_tracking(sending, recenter, centroid_x, livespeed, cpd, spd, ppd, tpd, mode, previousj1, previousj2, previousj3,previousj4, Ywid, Yheit)\n",
    "\n",
    "                                    if reached==True:\n",
    "                                        print('reached')\n",
    "                                        break \n",
    "                                else:\n",
    "                                    cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 255, 0), -1)  # Draw as green\n",
    "                        else:\n",
    "                            # If the priority mouse is not present, mark the first detected mouse as red\n",
    "                            if confidence == class_to_priority[specific_class]['confidence']:\n",
    "                                cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 0, 255), -1)\n",
    "                                print(f\"Centroid position: ({centroid_x}, {centroid_y})\")\n",
    "\n",
    "                                if centroid_y>300 or centroid_y<160: #if centroid y should be adjusted:\n",
    "                                    recenter=True\n",
    "\n",
    "                                reached, previousj2, previousj3=object_tracking(sending, recenter, centroid_x, livespeed, cpd, spd, ppd, tpd, mode, previousj1, previousj2, previousj3,previousj4, Ywid, Yheit)\n",
    "                                if reached==True:\n",
    "                                    print('reached')\n",
    "                                    break\n",
    "                            else:\n",
    "                                cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 255, 0), -1)\n",
    "\n",
    "                    else: \n",
    "                        stopcounter+=1\n",
    "                        print('object lost')\n",
    "                        if stopcounter>5:\n",
    "                            command='stop' \n",
    "                            (livespeed,cpd,spd,ppd,tpd,\n",
    "                            circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)   \n",
    "                            print(command, 'ped. Searching for object...')\n",
    "                            #send instruction\n",
    "                            bigmode=1\n",
    "\n",
    "                            if sending==True:\n",
    "                                pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "\n",
    "                            stopcounter=0\n",
    "            elif reached==True:\n",
    "                #grabbing\n",
    "                \n",
    "                \n",
    "                bigmode=0\n",
    "                if grabbed==False:\n",
    "                    j2,j3,previousj4=Yj2,Yj3,Yj4_s\n",
    "                    if previousj2<j2:\n",
    "                        previousj2+=1\n",
    "                    elif previousj2>j2:\n",
    "                        previousj2-=1\n",
    "                    if previousj3<j3:\n",
    "                        previousj3+=2\n",
    "                    elif previousj3>j3:\n",
    "                        previousj3-=2\n",
    "                    print (previousj2,previousj3)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "                    tolerance=3\n",
    "                    if abs(previousj2-j2)<=tolerance  and abs(previousj3-j3)<=tolerance:\n",
    "                        previousj4=Yj4_l\n",
    "                        if sending==True:\n",
    "                            for i in range(50):\n",
    "                                \n",
    "                                pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "                            \n",
    "                            grabbed=True\n",
    "                \n",
    "                if grabbed==True and put_box==False:\n",
    "                    #delay_time = 2  # 1-second delay\n",
    "\n",
    "                            # Sleep for the specified delay time\n",
    "                    #time.sleep(delay_time)\n",
    "                    j2,j3=121,110\n",
    "                    if previousj2<j2:\n",
    "                        previousj2+=2\n",
    "                    elif previousj2>j2:\n",
    "                        previousj2-=2\n",
    "                    if previousj3<j3:\n",
    "                        previousj3+=2\n",
    "                    elif previousj3>j3:\n",
    "                        previousj3-=2\n",
    "                    print (previousj2,previousj3)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "                        \n",
    "                    tolerance=3\n",
    "                    if abs(previousj2-j2)<=tolerance  and abs(previousj3-j3)<=tolerance:\n",
    "                        print('lifted')\n",
    "                        put_box=True\n",
    "                        \n",
    "                if put_box==True and dropped==False:\n",
    "                    \n",
    "                    j1,j2,j3,j4=-10,130,130,Yj4_l\n",
    "                    if previousj1<j1:\n",
    "                        previousj1+=1\n",
    "                    elif previousj1>j1:\n",
    "                        previousj1-=1\n",
    "                        \n",
    "                    if previousj2<j2:\n",
    "                        previousj2+=1\n",
    "                    elif previousj2>j2:\n",
    "                        previousj2-=1\n",
    "                        \n",
    "                    if previousj3<j3:\n",
    "                        previousj3+=2\n",
    "                    elif previousj3>j3:\n",
    "                        previousj3-=2\n",
    "                        \n",
    "                    print (previousj1,previousj2,previousj3,previousj4)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "                        \n",
    "                    tolerance=4\n",
    "                    if abs(previousj1-j1)<=tolerance and abs(previousj2-j2)<=tolerance  and abs(previousj3-j3)<=tolerance:\n",
    "                        previousj4=Yj4_s\n",
    "                        print('arrived')\n",
    "                        if sending==True:\n",
    "                            for i in range(50):\n",
    "                                \n",
    "                                pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed)\n",
    "                                print(previousj1, previousj2, previousj3, previousj4)\n",
    "                            \n",
    "\n",
    "                            dropped=True\n",
    "                            \n",
    "                if dropped==True:\n",
    "                    j1,j2,j3,j4=90,130,130,Yj4_s\n",
    "                    if previousj1<j1:\n",
    "                        previousj1+=1\n",
    "                    elif previousj1>j1:\n",
    "                        previousj1-=1\n",
    "                        \n",
    "                    if previousj2<j2:\n",
    "                        previousj2+=1\n",
    "                    elif previousj2>j2:\n",
    "                        previousj2-=1\n",
    "                        \n",
    "                    if previousj3<j3:\n",
    "                        previousj3+=2\n",
    "                    elif previousj3>j3:\n",
    "                        previousj3-=2\n",
    "                        \n",
    "                    print (previousj1,previousj2,previousj3,previousj4)\n",
    "                    if sending==True:\n",
    "\n",
    "                            \n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed)       \n",
    "                            \n",
    "            cv2.namedWindow('YOLO',cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        cap.release()\n",
    "        cv2.destroyWindow('YOLO')\n",
    "    elif mode=='orange': \n",
    "        stopcounter=0\n",
    "        specific_class='orange'\n",
    "        model=orange_model\n",
    "        Yj2 = 5\n",
    "        Yj3 = 65\n",
    "        Yj4_l = 160\n",
    "        Yj4_s = 120\n",
    "        Ywid = 210\n",
    "        Yheit = 200 \n",
    "        min_distance_threshold = 10\n",
    "        reached=False\n",
    "        grabbed=False\n",
    "        put_box=False\n",
    "        dropped=False\n",
    "        while cap.isOpened():\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            results= model(frame)\n",
    "            boxes = results.xyxy[0].cpu().numpy()  # Convert to numpy array      \n",
    "            class_to_priority = {} \n",
    "            recenter = False\n",
    "            priority_mouse_present = False\n",
    "            \n",
    "            if reached==False:\n",
    "                \n",
    "                for box in boxes:\n",
    "                    class_id = int(box[5])  # Extract class ID\n",
    "                    class_name = model.names[class_id]  # Convert class ID to class name\n",
    "                    confidence = box[4]\n",
    "\n",
    "                    if class_name == specific_class:\n",
    "                        centroid_x = (box[0] + box[2]) // 2  # Calculate centroid x-coordinate\n",
    "                        centroid_y = (box[1] + box[3]) // 2  # Calculate centroid y-coordinate\n",
    "                         # Check if the specific class is already assigned a priority\n",
    "                        if specific_class not in class_to_priority:\n",
    "                            # If not, assign the current object as the priority\n",
    "                            class_to_priority[specific_class] = {'centroid': (centroid_x, centroid_y), 'confidence': confidence}\n",
    "                        else:\n",
    "                            # If yes, compare the confidence with the current object\n",
    "                            if confidence > class_to_priority[specific_class]['confidence']:\n",
    "                                # If current object has higher confidence, update priority\n",
    "                                class_to_priority[specific_class] = {'centroid': (centroid_x, centroid_y), 'confidence': confidence}\n",
    "                        if (centroid_x, centroid_y) == class_to_priority[specific_class]['centroid']:\n",
    "                            priority_mouse_present = True\n",
    "\n",
    "                for box in boxes: \n",
    "                    class_id = int(box[5])  # Extract class ID\n",
    "                    class_name = model.names[class_id]  # Convert class ID to class name\n",
    "                    confidence = box[4]  # Extract confidence score\n",
    "                    x1, y1, x2, y2 = box[:4].astype(int)\n",
    "                    centroid_x = (x1 + x2) // 2\n",
    "                    centroid_y = (y1 + y2) // 2\n",
    "                    width = x2 - x1\n",
    "                    height = y2 - y1\n",
    "\n",
    "                    if class_name == specific_class:\n",
    "                        # Check if the priority mouse is present in the current frame\n",
    "                        if priority_mouse_present:\n",
    "                            # If the priority mouse is present, mark it as red\n",
    "                            if (centroid_x, centroid_y) == class_to_priority[specific_class]['centroid']:\n",
    "                                cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 0, 255), -1)\n",
    "                                print(f\"Centroid position: ({centroid_x}, {centroid_y}, {width}, {height})\")\n",
    "\n",
    "                                if centroid_y>300 or centroid_y<160: #if centroid y should be adjusted:\n",
    "                                    recenter=True\n",
    "                                reached, previousj2, previousj3 =object_tracking(sending, recenter, centroid_x, livespeed, cpd, spd, ppd, tpd, mode, previousj1, previousj2, previousj3,previousj4, Ywid, Yheit)\n",
    "                                if reached==True:\n",
    "                                    print('reached')\n",
    "                                    break  \n",
    "                            else:\n",
    "                                # Check if the distance between centroids is below the threshold\n",
    "                                priority_centroid_x, priority_centroid_y = class_to_priority[specific_class]['centroid']\n",
    "                                distance = np.sqrt((centroid_x - priority_centroid_x) ** 2 + (centroid_y - priority_centroid_y) ** 2)\n",
    "                                if distance < min_distance_threshold:\n",
    "                                    cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 0, 255), -1)  # Draw as red\n",
    "                                    print(f\"Centroid position: ({centroid_x}, {centroid_y})\")\n",
    "\n",
    "                                    if centroid_y>300 or centroid_y<160: #if centroid y should be adjusted:\n",
    "                                        recenter=True\n",
    "\n",
    "                                    reached, previousj2, previousj3=object_tracking(sending, recenter, centroid_x, livespeed, cpd, spd, ppd, tpd, mode, previousj1, previousj2, previousj3,previousj4, Ywid, Yheit)\n",
    "\n",
    "                                    if reached==True:\n",
    "                                        print('reached')\n",
    "                                        break \n",
    "                                else:\n",
    "                                    cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 255, 0), -1)  # Draw as green\n",
    "                        else:\n",
    "                            # If the priority mouse is not present, mark the first detected mouse as red\n",
    "                            if confidence == class_to_priority[specific_class]['confidence']:\n",
    "                                cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 0, 255), -1)\n",
    "                                print(f\"Centroid position: ({centroid_x}, {centroid_y})\")\n",
    "\n",
    "                                if centroid_y>300 or centroid_y<160: #if centroid y should be adjusted:\n",
    "                                    recenter=True\n",
    "\n",
    "                                reached, previousj2, previousj3=object_tracking(sending, recenter, centroid_x, livespeed, cpd, spd, ppd, tpd, mode, previousj1, previousj2, previousj3,previousj4, Ywid, Yheit)\n",
    "                                if reached==True:\n",
    "                                    print('reached')\n",
    "                                    break\n",
    "                            else:\n",
    "                                cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 255, 0), -1)\n",
    "\n",
    "                    else: \n",
    "                        stopcounter+=1\n",
    "                        print('object lost')\n",
    "                        if stopcounter>5:\n",
    "                            command='stop' \n",
    "                            (livespeed,cpd,spd,ppd,tpd,\n",
    "                            circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)   \n",
    "                            print(command, 'ped. Searching for object...')\n",
    "                            #send instruction\n",
    "                            bigmode=1\n",
    "\n",
    "                            if sending==True:\n",
    "                                pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "\n",
    "                            stopcounter=0\n",
    "            elif reached==True:\n",
    "                #grabbing\n",
    "                \n",
    "                \n",
    "                bigmode=0\n",
    "                if grabbed==False:\n",
    "                    j2,j3,previousj4=Yj2,Yj3,Yj4_s\n",
    "                    if previousj2<j2:\n",
    "                        previousj2+=1\n",
    "                    elif previousj2>j2:\n",
    "                        previousj2-=1\n",
    "                    if previousj3<j3:\n",
    "                        previousj3+=2\n",
    "                    elif previousj3>j3:\n",
    "                        previousj3-=2\n",
    "                    print (previousj2,previousj3)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "                    tolerance=3\n",
    "                    if abs(previousj2-j2)<=tolerance  and abs(previousj3-j3)<=tolerance:\n",
    "                        previousj4=Yj4_l\n",
    "                        if sending==True:\n",
    "                            for i in range(50):\n",
    "                                \n",
    "                                pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "\n",
    "                            \n",
    "                        \n",
    "                            grabbed=True\n",
    "                \n",
    "                if grabbed==True and put_box==False:\n",
    "                    #delay_time = 2  # 1-second delay\n",
    "\n",
    "                            # Sleep for the specified delay time\n",
    "                    #time.sleep(delay_time)\n",
    "                    j2,j3=121,110\n",
    "                    if previousj2<j2:\n",
    "                        previousj2+=2\n",
    "                    elif previousj2>j2:\n",
    "                        previousj2-=2\n",
    "                    if previousj3<j3:\n",
    "                        previousj3+=2\n",
    "                    elif previousj3>j3:\n",
    "                        previousj3-=2\n",
    "                    print (previousj2,previousj3)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "                        \n",
    "                    tolerance=3\n",
    "                    if abs(previousj2-j2)<=tolerance  and abs(previousj3-j3)<=tolerance:\n",
    "                        print('lifted')\n",
    "                        put_box=True\n",
    "                        \n",
    "                if put_box==True and dropped==False:\n",
    "                    \n",
    "                    j1,j2,j3,j4=-10,130,130,Yj4_l\n",
    "                    if previousj1<j1:\n",
    "                        previousj1+=1\n",
    "                    elif previousj1>j1:\n",
    "                        previousj1-=1\n",
    "                        \n",
    "                    if previousj2<j2:\n",
    "                        previousj2+=1\n",
    "                    elif previousj2>j2:\n",
    "                        previousj2-=1\n",
    "                        \n",
    "                    if previousj3<j3:\n",
    "                        previousj3+=2\n",
    "                    elif previousj3>j3:\n",
    "                        previousj3-=2\n",
    "                        \n",
    "                    print (previousj1,previousj2,previousj3,previousj4)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "                        \n",
    "                    tolerance=4\n",
    "                    if abs(previousj1-j1)<=tolerance and abs(previousj2-j2)<=tolerance  and abs(previousj3-j3)<=tolerance:\n",
    "                        previousj4=Yj4_s\n",
    "                        print('arrived')\n",
    "                        if sending==True:\n",
    "                            for i in range(50):\n",
    "                                \n",
    "                                pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed)\n",
    "                                print(previousj1, previousj2, previousj3, previousj4)\n",
    "                            \n",
    "\n",
    "                            dropped=True\n",
    "                            \n",
    "                if dropped==True:\n",
    "                    j1,j2,j3,j4=90,130,130,Yj4_s\n",
    "                    if previousj1<j1:\n",
    "                        previousj1+=1\n",
    "                    elif previousj1>j1:\n",
    "                        previousj1-=1\n",
    "                        \n",
    "                    if previousj2<j2:\n",
    "                        previousj2+=1\n",
    "                    elif previousj2>j2:\n",
    "                        previousj2-=1\n",
    "                        \n",
    "                    if previousj3<j3:\n",
    "                        previousj3+=2\n",
    "                    elif previousj3>j3:\n",
    "                        previousj3-=2\n",
    "                        \n",
    "                    print (previousj1,previousj2,previousj3,previousj4)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed)            \n",
    "                        \n",
    "            cv2.namedWindow('YOLO',cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        cap.release()\n",
    "        cv2.destroyWindow('YOLO')\n",
    "    \n",
    "    elif mode=='can': \n",
    "        stopcounter=0\n",
    "        specific_class='can'\n",
    "        model=default_model\n",
    "        Yj2 = 35\n",
    "        Yj3 = 85\n",
    "        Yj4_l = 200\n",
    "        Yj4_s = 100\n",
    "        Ywid = 210\n",
    "        Yheit = 270\n",
    "        min_distance_threshold = 10\n",
    "        reached=False\n",
    "        grabbed=False\n",
    "        put_box=False\n",
    "        dropped=False\n",
    "\n",
    "        look_for_object=True #new code  x 2\n",
    "        while cap.isOpened():\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            results= model(frame)\n",
    "            boxes = results.xyxy[0].cpu().numpy()  # Convert to numpy array      \n",
    "            class_to_priority = {} \n",
    "            recenter = False\n",
    "            priority_mouse_present = False\n",
    "            \n",
    "            if reached==False:\n",
    "                if look_for_object==True:  #new code\n",
    "                    initial_scan(livespeed, cpd, spd, ppd, tpd, mode)\n",
    "                \n",
    "                for box in boxes:\n",
    "                    class_id = int(box[5])  # Extract class ID\n",
    "                    class_name = model.names[class_id]  # Convert class ID to class name\n",
    "                    confidence = box[4]\n",
    "\n",
    "                    if class_name == specific_class:\n",
    "                        centroid_x = (box[0] + box[2]) // 2  # Calculate centroid x-coordinate\n",
    "                        centroid_y = (box[1] + box[3]) // 2  # Calculate centroid y-coordinate\n",
    "                         # Check if the specific class is already assigned a priority\n",
    "                        if specific_class not in class_to_priority:\n",
    "                            # If not, assign the current object as the priority\n",
    "                            class_to_priority[specific_class] = {'centroid': (centroid_x, centroid_y), 'confidence': confidence}\n",
    "                        else:\n",
    "                            # If yes, compare the confidence with the current object\n",
    "                            if confidence > class_to_priority[specific_class]['confidence']:\n",
    "                                # If current object has higher confidence, update priority\n",
    "                                class_to_priority[specific_class] = {'centroid': (centroid_x, centroid_y), 'confidence': confidence}\n",
    "                        if (centroid_x, centroid_y) == class_to_priority[specific_class]['centroid']:\n",
    "                            priority_mouse_present = True\n",
    "\n",
    "                for box in boxes:\n",
    "                    class_id = int(box[5])  # Extract class ID\n",
    "                    class_name = model.names[class_id]  # Convert class ID to class name\n",
    "                    confidence = box[4]  # Extract confidence score\n",
    "                    x1, y1, x2, y2 = box[:4].astype(int)\n",
    "                    centroid_x = (x1 + x2) // 2\n",
    "                    centroid_y = (y1 + y2) // 2\n",
    "                    width = x2 - x1\n",
    "                    height = y2 - y1\n",
    "\n",
    "                    if class_name == specific_class:\n",
    "\n",
    "                        look_for_object=False #new code  x 2\n",
    "                        # Check if the priority mouse is present in the current frame\n",
    "                        if priority_mouse_present:\n",
    "                            # If the priority mouse is present, mark it as red\n",
    "                            if (centroid_x, centroid_y) == class_to_priority[specific_class]['centroid']:\n",
    "                                cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 0, 255), -1)\n",
    "                                print(f\"Centroid position: ({centroid_x}, {centroid_y}, {width}, {height})\")\n",
    "\n",
    "                                if centroid_y>300 or centroid_y<160: #if centroid y should be adjusted:\n",
    "                                    recenter=True\n",
    "                                reached, previousj2, previousj3 =object_tracking(sending, recenter, centroid_x, livespeed, cpd, spd, ppd, tpd, mode, previousj1, previousj2, previousj3,previousj4, Ywid, Yheit)\n",
    "                                if reached==True:\n",
    "                                    print('reached')\n",
    "                                    break  \n",
    "                            else:\n",
    "                                # Check if the distance between centroids is below the threshold\n",
    "                                priority_centroid_x, priority_centroid_y = class_to_priority[specific_class]['centroid']\n",
    "                                distance = np.sqrt((centroid_x - priority_centroid_x) ** 2 + (centroid_y - priority_centroid_y) ** 2)\n",
    "                                if distance < min_distance_threshold:\n",
    "                                    cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 0, 255), -1)  # Draw as red\n",
    "                                    print(f\"Centroid position: ({centroid_x}, {centroid_y})\")\n",
    "\n",
    "                                    if centroid_y>300 or centroid_y<160: #if centroid y should be adjusted:\n",
    "                                        recenter=True\n",
    "\n",
    "                                    reached, previousj2, previousj3=object_tracking(sending, recenter, centroid_x, livespeed, cpd, spd, ppd, tpd, mode, previousj1, previousj2, previousj3,previousj4, Ywid, Yheit)\n",
    "\n",
    "                                    if reached==True:\n",
    "                                        print('reached')\n",
    "                                        break \n",
    "                                else:\n",
    "                                    cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 255, 0), -1)  # Draw as green\n",
    "                        else:\n",
    "                            # If the priority mouse is not present, mark the first detected mouse as red\n",
    "                            if confidence == class_to_priority[specific_class]['confidence']:\n",
    "                                cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 0, 255), -1)\n",
    "                                print(f\"Centroid position: ({centroid_x}, {centroid_y})\")\n",
    "\n",
    "                                if centroid_y>300 or centroid_y<160: #if centroid y should be adjusted:\n",
    "                                    recenter=True\n",
    "\n",
    "                                reached, previousj2, previousj3=object_tracking(sending, recenter, centroid_x, livespeed, cpd, spd, ppd, tpd, mode, previousj1, previousj2, previousj3,previousj4, Ywid, Yheit)\n",
    "                                if reached==True:\n",
    "                                    print('reached')\n",
    "                                    break\n",
    "                            else:\n",
    "                                cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 255, 0), -1)\n",
    "\n",
    "                    else: \n",
    "                        stopcounter+=1\n",
    "                        print('object lost')\n",
    "                        if stopcounter>5:\n",
    "                            command='stop' \n",
    "                            (livespeed,cpd,spd,ppd,tpd,\n",
    "                            circle_dir,square_dir, plus_dir,triangle_dir) = driving(command, livespeed, cpd, spd, ppd, tpd, mode)   \n",
    "                            print(command, 'ped. Searching for object...')\n",
    "                            #send instruction\n",
    "                            bigmode=1\n",
    "\n",
    "                            look_for_object=True #new code  x 2\n",
    "\n",
    "                            if sending==True:\n",
    "                                pass_instruction_base(bigmode, circle_dir, square_dir, plus_dir, triangle_dir, livespeed)\n",
    "\n",
    "                            stopcounter=0\n",
    "\n",
    "            elif reached==True:\n",
    "                #grabbing\n",
    "                \n",
    "                \n",
    "                bigmode=0\n",
    "                if grabbed==False and put_box==False:\n",
    "                    j2,j3=Yj2,Yj3\n",
    "                    if previousj2<j2:\n",
    "                        previousj2+=1\n",
    "                    elif previousj2>j2:\n",
    "                        previousj2-=1\n",
    "                    if previousj3<j3:\n",
    "                        previousj3+=2\n",
    "                    elif previousj3>j3:\n",
    "                        previousj3-=2\n",
    "\n",
    "                    print (previousj2,previousj3,previousj4)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "                    tolerance=3\n",
    "                    if abs(previousj2-j2)<=tolerance and abs(previousj3-j3)<=tolerance:\n",
    "                        j4=Yj4_l\n",
    "                        if previousj4<j4:\n",
    "                            previousj4+=5\n",
    "                        elif previousj4>j4:\n",
    "                            previousj4-=5\n",
    "                        if sending==True:\n",
    "                            pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed)\n",
    "                            \n",
    "                            if abs(previousj4-j4)<7:\n",
    "                                grabbed=True\n",
    "                \n",
    "                if grabbed==True and put_box==False:\n",
    "                    #delay_time = 2  # 1-second delay\n",
    "\n",
    "                            # Sleep for the specified delay time\n",
    "                    #time.sleep(delay_time)\n",
    "                    j2,j3=121,110\n",
    "                    if previousj2<j2:\n",
    "                        previousj2+=2\n",
    "                    elif previousj2>j2:\n",
    "                        previousj2-=2\n",
    "                    if previousj3<j3:\n",
    "                        previousj3+=2\n",
    "                    elif previousj3>j3:\n",
    "                        previousj3-=2\n",
    "                    print (previousj2,previousj3)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "                        \n",
    "                    tolerance=3\n",
    "                    if abs(previousj2-j2)<=tolerance and abs(previousj3-j3)<=tolerance:\n",
    "                        print('lifted')\n",
    "                        put_box=True\n",
    "                        \n",
    "                if put_box==True and dropped==False:\n",
    "                    \n",
    "                    j1,j2,j3=-10,130,130\n",
    "                    if previousj1<j1:\n",
    "                        previousj1+=2\n",
    "                    elif previousj1>j1:\n",
    "                        previousj1-=2\n",
    "                        \n",
    "                    if previousj2<j2:\n",
    "                        previousj2+=1\n",
    "                    elif previousj2>j2:\n",
    "                        previousj2-=1\n",
    "                        \n",
    "                    if previousj3<j3:\n",
    "                        previousj3+=2\n",
    "                    elif previousj3>j3:\n",
    "                        previousj3-=2\n",
    "                        \n",
    "\n",
    "                        \n",
    "                    print (previousj1,previousj2,previousj3,previousj4)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "                        \n",
    "                    tolerance=4\n",
    "                    if abs(previousj1-j1)<=tolerance and abs(previousj2-j2)<=tolerance and abs(previousj3-j3)<=tolerance:\n",
    "                        j4=Yj4_s\n",
    "                        print('arrived')\n",
    "                        \n",
    "                        if previousj4<j4:\n",
    "                            previousj4+=5\n",
    "                        elif previousj4>j4:\n",
    "                            previousj4-=5\n",
    "                            \n",
    "                        if sending==True:\n",
    "                            pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed)\n",
    "                            \n",
    "                            if abs(previousj4-j4)<6:\n",
    "                                dropped=True\n",
    "                                \n",
    "                            print(previousj1, previousj2, previousj3, previousj4)\n",
    "\n",
    "\n",
    "                           \n",
    "                            \n",
    "                if dropped==True:\n",
    "                    j1,j2,j3,j4=90,130,130,Yj4_s\n",
    "                    if previousj1<j1:\n",
    "                        previousj1+=2\n",
    "                    elif previousj1>j1:\n",
    "                        previousj1-=2\n",
    "                        \n",
    "                    if previousj2<j2:\n",
    "                        previousj2+=1\n",
    "                    elif previousj2>j2:\n",
    "                        previousj2-=1\n",
    "                        \n",
    "                    if previousj3<j3:\n",
    "                        previousj3+=2\n",
    "                    elif previousj3>j3:\n",
    "                        previousj3-=2\n",
    "                        \n",
    "                    print (previousj1,previousj2,previousj3,previousj4)\n",
    "                    if sending==True:\n",
    "                        pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "\n",
    "                            \n",
    "                            \n",
    "            cv2.namedWindow('YOLO',cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        cap.release()\n",
    "        cv2.destroyWindow('YOLO')\n",
    "    elif mode=='quit':\n",
    "        bigmode=0\n",
    "        j2,j3=120,150\n",
    "        while (abs(previousj2-j2)>2) or (abs(previousj3-j3)>2):\n",
    "            if previousj2<j2:\n",
    "                previousj2+=2\n",
    "            elif previousj2>j2:\n",
    "                previousj2-=2\n",
    "            if previousj3<j3:\n",
    "                previousj3+=2\n",
    "            elif previousj3>j3:\n",
    "                previousj3-=2\n",
    "            print (previousj2,previousj3)\n",
    "            if sending==True:\n",
    "                pass_instruction_arm(bigmode, previousj1, previousj2, previousj3, previousj4, livespeed) \n",
    "                delay_time = 0.05  # 0.05 s delay\n",
    "\n",
    "                # Sleep for the specified delay time\n",
    "                time.sleep(delay_time)\n",
    "        #run=False\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "#port1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5cfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd327a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
